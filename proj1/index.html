<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>

<body>
	<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
	<h1 align="middle">Project 1: Rasterizer</h1>
	<h2 align="middle">Yifan Zhong, Yicheng Sun, CS184-Spring 2022</h2>

	<br><br>
	
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Overview</h2>
	<p>Give a high-level overview of what you implemented in this project. Think about what you've built as a whole. Share
		your thoughts on what interesting things you've learned from completing the project.</p>
	
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 1: Drawing Single-Color Triangles</h2>
	<h3>Helper Functions</h3>
	<ol>
		<li>
			<p><i>/* check if the sample point(px, py) is in the triangle */</i></p>
			<p><i>bool inTri(float px, float py, float ax, float ay, float bx, float by, float cx, float cy) {...}</i></p>
		</li>
		<li>
			<p><i>/* check whether the point is inside or outside edge */</i></p>
			<p><i>float l(float px, float py, float p0x, float p0y, float p1x, float p1y) {...}</i></p>
		</li>
		<li>
			<p><i>/* normalize the number to resolve the precision issue of floating-point numbers during comparison */</i></p>
			<p><i>int normalize_l(float f) {...}</i></p>
		</li>
	</ol>
	<h3>Algorithms Workthrough</h3>
	<ol>
		<li>
			We calculate the maximum and minimum value of x and y in the triangle to limit our iteration in a smaller
			rectangular
			<ul>
				<li><i>max_x = (int) max({x0, x1, x2}) + 1;</i></li>
				<li><i>max_y = (int) max({y0, y1, y2}) + 1;</i></li>
				<li><i>min_x = (int) min({x0, x1, x2});</i></li>
				<li><i>min_y = (int) min({y0, y1, y2});</i></li>
				<li>We add 1 to the maximum value to ensure that all parts of the triangle are in the rectangle.</li>
				<li>
					Since we only test the points within the rectangular space, this algorithms is no worse than the one
					that check each sample within the bounding box.
				</li>
			</ul>
		</li>
		<li>
			We setup a nested for loop to iterate through each pixel from the top left corner to the bottom right
			corner.
		</li>
		<li>
			For each point <i>(x, y)</i>, we first get the central value of the pixel <i>(x+0.5, y+0.5)</i> and pass it
			to <i>inTri()</i>.
		</li>
		<li>
			<i>inTri()</i> takes three vertices of the triangle and the sample point as parameters, and calls <i>l()</i>
			for each edge of the triangle.
		</li>
		<li>
			With three return values from <i>l()</i>, we first normalize them to resolve the percision issue when comparing
			with 0 by calling <i>normalize_l()</i>, <i>inTri()</i> check if all of them have the same sign, which eliminate
			the issue caused by winding order of the vertices.
		</li>
	</ol>
	<h3>Optimization for Extra Credit</h3>
	<ul>
		<li>
			When we iterate through along a row/column, once we step out of the triangle, we will never return back to
			the triangle on that row/column.
			<ol>
				<li>
					We set a condition to step out of the inner loop once we cross the bottom edge of the triangle.
				</li>
				<li>
					We initialize a flag <i>bool y_flag = false</i> in the outer loop. Once we enter the triangle, set
					flag to be true.
				</li>
				<li>
					During the inner loop, if we find that the <i>y_flag</i> change from <i>true</i> to <i>false</i>, we
					break the loop.
				</li>
			</ol>
		</li>
		<li>
			<p>Timing Comparison Table</p>
			<img src="./images/time_comp.png" alt="Time Comparison Table">
		</li>
	</ul>
	<h3>Sample Output</h3>
	<ul>
		<li>
			The pixel inspector is centered on the upper vertex of the purple triangle. The triangle is discontinuous at
			this point.
		</li>
	</ul>
	<img src="./images/task1_t4.png" alt="Task 1 Test 4" width="700" height="500">

	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 2: Antialiasing by Supersampling</h2>
	<h3>Algorithms Workthrough</h3>
	<ul>
		<li>
			In <i>RasterizerImp::rasterize_triangle()</i>
			<ol>
				<li>
					Similar to what we did for task 1, we first get the max and min value of x and y to setup a loop
					from upper left corner to bottom right corner of the bounding box.
				</li>
				<li>
					Using the sample_rate initialized in RasterizerImp, we calculate the number of samples per edge
					<i>int r = (int) sqrt(this->sample_rate);</i>.
				</li>
				<li>
					In addition to the nested for loop from task 1, we add another two nested loops to iterate through
					subparts of each pixel. We call <i>inTri()</i> for each sample point similar to task 1.
				</li>
				<li>
					One thing to note is that since we are evaluating the subpart of each pixel, the x, y value for the
					sample point change to <i>(x+(i+0.5)/r, y+(j+0.5)/r)</i>. Here, i is the sampling position on the
					x-coordinate, j is the sampling position on the y-coordinate. The following image shows the relations 
					between x, y and i, j when the sample rate is 4.
				</li>
				<img src="./images/supersampling_example.png" width="400" height="400">
				<li>
					Instead of rasterize the sample point directly, we add it to the sample_buffer at index of <i>y * width
					+ x * this->sample_rate + i * r + j</i>.
				</li>
				<li>
					<i>y * width + x</i> locates the pixel we are supersampling, and <i>i * r + j</i> locates the sample
					point within the pixel.
				</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::set_sample_rate()</i>:
			<ol>
				<li>We change the first parameter of <i>resize()</i> from <i>width * height</i> to <i>width * height *rate</i>.</li>
				<li>We add a call to clear_buffer() to clear the sample buffer after resize.</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::set_framebuffer_target()</i>:
			<ol>
				<li>We change the first parameter of <i>resize()</i> to <i>width * height * rate</i> as well.</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::fill_pixel()</i>:
			<ol>
				<li>Since we are supersampling a higher resolution image first, the index for the pixel to fill in sample_buffer becomes a
				sample point. The index changes to <i>(y * width + x) * this->sample_rate + i</i>, and we need to loop sample_rate times
				to fill the entire pixel with color c.</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::resolve_to_framebuffer()</i>:
			<ol>
				<li>For each pixel point, we create a <i>temp_color[]</i> array to store the floating RGB values. We then iterate over each sample point within the current pixel to obtain the net RGB value for that pixel.</li>
				<li>Note that the index of the current sample point is <i>(y * width + x) * this->sample_rate + i</i> where i is the value from 0 to <i>this->sample_rate</i>.</li>
				<li>We average the RGB net values to obtain the color of the pixel after supersampling.</li>
				<li>Finally, similar to the original code in this function, we call <i>rgb_framebuffer_target()</i> to render the frame.</li>
			</ol>
		</li>
		<li>
			<p>Different from the original rasterizer pipeline, we first supersampling the image by simple_rate and before eventually
			populating the pixel, we will downsampling the pixel and take the average of the pixel color.</p>
		</li>
	</ul>
	<h3>Sample Output</h3>
	<p>As supersampling rate increate, we are sampling finer in each pixel. At the upper side of the triangle, since the corner
	is extremely skinny, less sample points are categorized as be in the triangle. Thus, the color value of that corner is
	getting lighter after averaging over the whole pixel. Moreover, as we approaching the corner vertex, higher sampling
	rate will result in lighter color.</p>
	<div align="middle">
		<table style="width: 100%">
			<tr>
				<td>
					<img src="./images/sample_rate_1.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 1</figcaption>
				</td>
				<td>
					<img src="./images/sample_rate_4.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 4</figcaption>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<img src="./images/sample_rate_9.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 9</figcaption>
				</td>
				<td>
					<img src="./images/sample_rate_16.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 16</figcaption>
				</td>
			</tr>
		</table>
	</div>
	<h3>Extra Credit</h3>
	<ol>
		<li>xxxxxxxxxxxxxxxxxxxxxxxxxxxx</li>
		<li>xxxxxxxxxxxxxx</li>
		<li>xxxxxxx</li>
	</ol>
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 3: Transforms</h2>
	<h3>Cubeman</h3>
	<ol>
		<li>We apply rotation and transition to each part of the cubeman respectively to make it look like he was jumping.</li>
		<li>We also changed the color of his head to blue and half of his arms and legs to skin color to make it look like he is
		wearing short sleeves and shorts.</li>
		<li>Finally we apply scale to the whole robot to make it bigger.</li>
		<img src="./images/cubeman.png" alt="cubeman" width="500" height="500">
	</ol>
	<h3>Extra Credit</h3>
	<ol>
		<li>xxxxxxxxxxxxxxxxxxxxxxxxxxxx</li>
		<li>xxxxxxxxxxxxxx</li>
		<li>xxxxxxx</li>
	</ol>
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 4: Barycentric coordinates</h2>
	<h3>Barycentric Coordinate Explanation</h3>
	<p>The barycycentric coordinate let us represent a point with three vertices of the triangle. Each point is represented
		by 3 values. Three vetices are (1, 0, 0), (0, 1, 0), (0, 0, 1) respectively. If we assign one of the full values of
		RGB to the three vertices, we can use the coordinate of the point to assign the gradient ramp to the triangle.</p>
	<img src="./images/barycentric coordinates.png" alt="barycentric coordinates" width="500" height="500">
	<h3>Test 7 Output</h3>
	<img src="./images/task4_test7.png" alt="task 4, test 7" width="700" height="500">

	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 5: "Pixel sampling" for texture mapping</h2>
	<h3>Texture Mapping</h3>
	<ol>
		<li>
			Pixel sampling uses the information we now have about the surrounding pixels to get texture information for the new
			pixels. When we zoom in on the image, the original texture is spread out over a larger area. Therefore, we need to map
			through the original texture to the additional pixel points.
		</li>
		<li>
			Nearest Neighbor: by comparing the distance between the current pixel and 4 surrounding pixels, we assign the texture
			information of the nearest pixel to the current pixel.
		</li>
		<li>
			Bilinear Sampling: different from nearest neighbor, bilinear sampling combines the texture information of four pixel points
			around the sampling pixel proportionally.
		</li>
		<li>
			The most significant difference between nearest neighbor and bilinear sampling is that nearest neighbor only takes the value
			of one existing pixel while bilinear sampling combines four pixels and make the sampling process more smooth.
		</li>
	</ol>
	<h3>Test Outputs</h3>
	<div align="middle">
		<table style="width: 100%">
			<tr>
				<td>
					<img src="./images/nearest_1.png" align="middle" width="500px" />
					<figcaption align="middle">Nearest Neighbor with 1 sample/pixel</figcaption>
				</td>
				<td>
					<img src="./images/nearest_16.png" align="middle" width="500px" />
					<figcaption align="middle">Nearest Neighbor with 16 samples/pixel</figcaption>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<img src="./images/bilinear_1.png" align="middle" width="500px" />
					<figcaption align="middle">Bilinear sampling with 1 sample/pixel</figcaption>
				</td>
				<td>
					<img src="./images/bilinear_16.png" align="middle" width="500px" />
					<figcaption align="middle">Bilinear sampling with 16 samples/pixel</figcaption>
				</td>
			</tr>
		</table>
	</div>
	<h3>Comment on the Output</h3>
	<ul>
		<li>
			The result shows that using bilinear sampling with 16 samples per pixel will have the most great image and the one that
			using nearest neighbor with 1 sample per pixel will have the most aliased image.
		</li>
		<li>
			Comparing supersampling image with bilinear sampling image, we can see that supersampling can have a better overall affects
			in anti-aliasing. However, due to the high cost of supersampling, bilinear sampling can also be a great choice in most cases.
		</li>
		<li>
			There will be a large difference between these two methods if the image we rendering have hight frequency. In this case, the
			nearest neighbor may not be able to capture as much details as bilinear sampling and may be easiler to be effected by redundant
			texture information.
		</li>
	</ul>



	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">GitHub Page Link</h2>
	<p align="middle" style="font-size: 150%;">
		<a href="https://cal-cs184-student.github.io/sp22-project-webpages-Chyvannn/">
			https://cal-cs184-student.github.io/sp22-project-webpages-Chyvannn/
		</a>
	</p>
</body>

</html>