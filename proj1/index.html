<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>

<body>
	<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
	<h1 align="middle">Project 1: Rasterizer</h1>
	<h2 align="middle">Yifan Zhong, Yicheng Sun, CS184-Spring 2022</h2>

	<br><br>
	
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Overview</h2>
	<p align="middle">
		In this project, we built a rasterizer which can be used to render an image with diffent rasterizing techniques. We
		first implement the algorithms to asterizing an image and speed it up in task 1. We then focus on making the image more
		clear using supersampling in task 2. In task 3, we shift the gear to change out focus onto simple transforms including
		rotating, scaling, and transiting. We then applied the concept of barycentric coordinates to achieve the gradient of
		colors in task 4. We then further implement nearest neighbor and bilinear sampling to make the renderized image better.
		Finally, in task 6, we implement level sampling to sample at different mipmap levels. To sum up, the rasterizer we built
		equipped with different ways to get a better quality image.
	</p>
	
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 1: Drawing Single-Color Triangles</h2>
	<h3>Helper Functions</h3>
	<ol>
		<li>
			<p><i>/* check if the sample point(px, py) is in the triangle */</i></p>
			<p><i>bool inTri(float px, float py, float ax, float ay, float bx, float by, float cx, float cy) {...}</i></p>
		</li>
		<li>
			<p><i>/* check whether the point is inside or outside edge */</i></p>
			<p><i>float l(float px, float py, float p0x, float p0y, float p1x, float p1y) {...}</i></p>
		</li>
		<li>
			<p><i>/* normalize the number to resolve the precision issue of floating-point numbers during comparison */</i></p>
			<p><i>int normalize_l(float f) {...}</i></p>
		</li>
	</ol>
	<h3>Algorithms Workthrough</h3>
	<ol>
		<li>
			We calculate the maximum and minimum value of x and y in the triangle to limit our iteration in a smaller
			rectangular
			<ul>
				<li><i>max_x = (int) max({x0, x1, x2}) + 1;</i></li>
				<li><i>max_y = (int) max({y0, y1, y2}) + 1;</i></li>
				<li><i>min_x = (int) min({x0, x1, x2});</i></li>
				<li><i>min_y = (int) min({y0, y1, y2});</i></li>
				<li>We add 1 to the maximum value to ensure that all parts of the triangle are in the rectangle.</li>
				<li>
					Since we only test the points within the rectangular space, this algorithms is no worse than the one
					that check each sample within the bounding box.
				</li>
			</ul>
		</li>
		<li>
			We setup a nested for loop to iterate through each pixel from the top left corner to the bottom right
			corner.
		</li>
		<li>
			For each point <i>(x, y)</i>, we first get the central value of the pixel <i>(x+0.5, y+0.5)</i> and pass it
			to <i>inTri()</i>.
		</li>
		<li>
			<i>inTri()</i> takes three vertices of the triangle and the sample point as parameters, and calls <i>l()</i>
			for each edge of the triangle.
		</li>
		<li>
			With three return values from <i>l()</i>, we first normalize them to resolve the percision issue when comparing
			with 0 by calling <i>normalize_l()</i>, <i>inTri()</i> check if all of them have the same sign, which eliminate
			the issue caused by winding order of the vertices.
		</li>
	</ol>
	<h3>Optimization for Extra Credit</h3>
	<ul>
		<li>
			When we iterate through along a row/column, once we step out of the triangle, we will never return back to
			the triangle on that row/column.
			<ol>
				<li>
					We set a condition to step out of the inner loop once we cross the bottom edge of the triangle.
				</li>
				<li>
					We initialize a flag <i>bool y_flag = false</i> in the outer loop. Once we enter the triangle, set
					flag to be true.
				</li>
				<li>
					During the inner loop, if we find that the <i>y_flag</i> change from <i>true</i> to <i>false</i>, we
					break the loop.
				</li>
			</ol>
		</li>
		<li>
			<p>Timing Comparison Table</p>
			<img src="./images/time_comp.png" alt="Time Comparison Table">
		</li>
	</ul>
	<h3>Sample Output</h3>
	<ul>
		<li>
			The pixel inspector is centered on the upper vertex of the purple triangle. The triangle is discontinuous at
			this point.
		</li>
	</ul>
	<img src="./images/task1_t4.png" alt="Task 1 Test 4" width="700" height="500">

	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 2: Antialiasing by Supersampling</h2>
	<h3>Algorithms Workthrough</h3>
	<ul>
		<li>
			In <i>RasterizerImp::rasterize_triangle()</i>
			<ol>
				<li>
					Similar to what we did for task 1, we first get the max and min value of x and y to setup a loop
					from upper left corner to bottom right corner of the bounding box.
				</li>
				<li>
					Using the sample_rate initialized in RasterizerImp, we calculate the number of samples per edge
					<i>int r = (int) sqrt(this->sample_rate);</i>.
				</li>
				<li>
					In addition to the nested for loop from task 1, we add another two nested loops to iterate through
					subparts of each pixel. We call <i>inTri()</i> for each sample point similar to task 1.
				</li>
				<li>
					One thing to note is that since we are evaluating the subpart of each pixel, the x, y value for the
					sample point change to <i>(x+(i+0.5)/r, y+(j+0.5)/r)</i>. Here, i is the sampling position on the
					x-coordinate, j is the sampling position on the y-coordinate. The following image shows the relations 
					between x, y and i, j when the sample rate is 4.
				</li>
				<img src="./images/supersampling_example.png" width="400" height="400">
				<li>
					Instead of rasterize the sample point directly, we add it to the sample_buffer at index of <i>y * width
					+ x * this->sample_rate + i * r + j</i>.
				</li>
				<li>
					<i>y * width + x</i> locates the pixel we are supersampling, and <i>i * r + j</i> locates the sample
					point within the pixel.
				</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::set_sample_rate()</i>:
			<ol>
				<li>We change the first parameter of <i>resize()</i> from <i>width * height</i> to <i>width * height *rate</i>.</li>
				<li>We add a call to clear_buffer() to clear the sample buffer after resize.</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::set_framebuffer_target()</i>:
			<ol>
				<li>We change the first parameter of <i>resize()</i> to <i>width * height * rate</i> as well.</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::fill_pixel()</i>:
			<ol>
				<li>Since we are supersampling a higher resolution image first, the index for the pixel to fill in sample_buffer becomes a
				sample point. The index changes to <i>(y * width + x) * this->sample_rate + i</i>, and we need to loop sample_rate times
				to fill the entire pixel with color c.</li>
			</ol>
		</li>
		<li>
			In <i>RasterizerImp::resolve_to_framebuffer()</i>:
			<ol>
				<li>For each pixel point, we create a <i>temp_color[]</i> array to store the floating RGB values. We then iterate over each sample point within the current pixel to obtain the net RGB value for that pixel.</li>
				<li>Note that the index of the current sample point is <i>(y * width + x) * this->sample_rate + i</i> where i is the value from 0 to <i>this->sample_rate</i>.</li>
				<li>We average the RGB net values to obtain the color of the pixel after supersampling.</li>
				<li>Finally, similar to the original code in this function, we call <i>rgb_framebuffer_target()</i> to render the frame.</li>
			</ol>
		</li>
		<li>
			<p>Different from the original rasterizer pipeline, we first supersampling the image by simple_rate and before eventually
			populating the pixel, we will downsampling the pixel and take the average of the pixel color.</p>
		</li>
	</ul>
	<h3>Sample Output</h3>
	<p>As supersampling rate increate, we are sampling finer in each pixel. At the upper side of the triangle, since the corner
	is extremely skinny, less sample points are categorized as be in the triangle. Thus, the color value of that corner is
	getting lighter after averaging over the whole pixel. Moreover, as we approaching the corner vertex, higher sampling
	rate will result in lighter color.</p>
	<div align="middle">
		<table style="width: 100%">
			<tr>
				<td>
					<img src="./images/sample_rate_1.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 1</figcaption>
				</td>
				<td>
					<img src="./images/sample_rate_4.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 4</figcaption>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<img src="./images/sample_rate_9.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 9</figcaption>
				</td>
				<td>
					<img src="./images/sample_rate_16.png" align="middle" width="500px" />
					<figcaption align="middle">Supersample rate: 16</figcaption>
				</td>
			</tr>
		</table>
	</div>
	<h3>Extra Credit</h3>
	<ol>
		<li>xxxxxxxxxxxxxxxxxxxxxxxxxxxx</li>
		<li>xxxxxxxxxxxxxx</li>
		<li>xxxxxxx</li>
	</ol>
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 3: Transforms</h2>
	<h3>Cubeman</h3>
	<ol>
		<li>We apply rotation and transition to each part of the cubeman respectively to make it look like he was jumping.</li>
		<li>We also changed the color of his head to blue and half of his arms and legs to skin color to make it look like he is
		wearing short sleeves and shorts.</li>
		<li>Finally we apply scale to the whole robot to make it bigger.</li>
		<img src="./images/cubeman.png" alt="cubeman" width="500" height="500">
	</ol>
	<h3>Extra Credit</h3>
	<ol>
		<li>xxxxxxxxxxxxxxxxxxxxxxxxxxxx</li>
		<li>xxxxxxxxxxxxxx</li>
		<li>xxxxxxx</li>
	</ol>
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 4: Barycentric coordinates</h2>
	<h3>Barycentric Coordinate Explanation</h3>
	<p>The barycycentric coordinate let us represent a point with three vertices of the triangle. Each point is represented
		by 3 values. Three vetices are (1, 0, 0), (0, 1, 0), (0, 0, 1) respectively. If we assign one of the full values of
		RGB to the three vertices, we can use the coordinate of the point to assign the gradient ramp to the triangle.</p>
	<img src="./images/barycentric_coordinates.png" alt="barycentric coordinates" width="500" height="500">
	<h3>Test 7 Output</h3>
	<img src="./images/color_gradients.png" alt="task 4, test 7" width="700" height="500">

	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 5: "Pixel sampling" for texture mapping</h2>
	<h3>Texture Mapping</h3>
	<ol>
		<li>
			Pixel sampling uses the information we now have about the surrounding pixels to get texture information for the new
			pixels. When we zoom in on the image, the original texture is spread out over a larger area. Therefore, we need to map
			through the original texture to the additional pixel points.
		</li>
		<li>
			Nearest Neighbor: by comparing the distance between the current pixel and 4 surrounding pixels, we assign the texture
			information of the nearest pixel to the current pixel.
		</li>
		<li>
			Bilinear Sampling: different from nearest neighbor, bilinear sampling combines the texture information of four pixel points
			around the sampling pixel proportionally.
		</li>
		<li>
			The most significant difference between nearest neighbor and bilinear sampling is that nearest neighbor only takes the value
			of one existing pixel while bilinear sampling combines four pixels and make the sampling process more smooth.
		</li>
	</ol>
	<h3>Test Outputs</h3>
	<div align="middle">
		<table style="width: 100%">
			<tr>
				<td>
					<img src="./images/nearest_1.png" align="middle" width="500px" />
					<figcaption align="middle">Nearest Neighbor with 1 sample/pixel</figcaption>
				</td>
				<td>
					<img src="./images/nearest_16.png" align="middle" width="500px" />
					<figcaption align="middle">Nearest Neighbor with 16 samples/pixel</figcaption>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<img src="./images/bilinear_1.png" align="middle" width="500px" />
					<figcaption align="middle">Bilinear sampling with 1 sample/pixel</figcaption>
				</td>
				<td>
					<img src="./images/bilinear_16.png" align="middle" width="500px" />
					<figcaption align="middle">Bilinear sampling with 16 samples/pixel</figcaption>
				</td>
			</tr>
		</table>
	</div>
	<h3>Comment on the Output</h3>
	<ul>
		<li>
			The result shows that using bilinear sampling with 16 samples per pixel will have the most great image and the one that
			using nearest neighbor with 1 sample per pixel will have the most aliased image.
		</li>
		<li>
			Comparing supersampling image with bilinear sampling image, we can see that supersampling can have a better overall affects
			in anti-aliasing. However, due to the high cost of supersampling, bilinear sampling can also be a great choice in most cases.
		</li>
		<li>
			There will be a large difference between these two methods if the image we rendering have hight frequency. In this case, the
			nearest neighbor may not be able to capture as much details as bilinear sampling and may be easiler to be effected by redundant
			texture information.
		</li>
	</ul>
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Task 6: "Level sampling" with mipmaps for texture mapping</h2>
	<h3>Level Sampling</h3>
	<ul>
		<li>
			To map our image from the screen space to the texture space, some part of the image will be concentrated while other
			parts maybe less compacted. In this case, some part of the image may have the resolution higher than necessary while
			other parts may use lower sample rate. To get the texture of different resolution, we store them in a mipmap. Whenever
			we wand an image with higher resolution, we can choose a higher level mipmap image. If we need a lower resolution image,
			we can use a lower level mipmap image. Thus, the overall resolution of the image can be changed dynamically base on the
			current texture.
		</li>
		<li>
			<p>
				To implement level mapping, we first want to implement get_level() function. In this case, we can make use of the
				barycentric coordinates method we implemented in task 5. After getting (u, v), we calculate the value of (du/dx,
				dv/dx) and (du/dy, dv/dy). With these values, we can perform the process in slides showed as below.
			</p>
			<img src="./images/text_map_into.png" align="middle" width="800px" height = "600px">
		</li>
	</ul>
	<h3>Test Output></h3>
	<div align="middle">
		<table style="width: 100%">
			<tr>
				<td>
					<img src="./images/l_z_p_n.png" align="middle" width="500px" />
					<figcaption align="middle">Zero Level + Nearst Sampling</figcaption>
				</td>
				<td>
					<img src="./images/l_z_p_l.png" align="middle" width="500px" />
					<figcaption align="middle">Zero Level + Bilinear Sampling</figcaption>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<img src="./images/l_n_p_n.png" align="middle" width="500px" />
					<figcaption align="middle">Nearest Level + Nearst Sampling</figcaption>
				</td>
				<td>
					<img src="./images/l_n_p_l.png" align="middle" width="500px" />
					<figcaption align="middle">Nearest Level + Bilinear Sampling</figcaption>
				</td>
			</tr>
		</table>
	</div>
	<ul>
		<li>
			In these sampling patterns, supersampling is the one that requires a lot more memory than others. With the inceasing of
			sample rate, we will need to also increase the memory used to save the pixel information with the same factor.
		</li>
		<li>
			On the other hand, level sampling will requires more time to process due to multiple levels in the mipmap to be
			considered and combined.
		</li>
		<li>Here, nearest sampling can be one of the cheapest in terms of both memory and time, but its image quality will also reduece significantly.</li>
		<li>For binear sampling, since we only need to consider 4 more points for each pixel, the time we used my increase slightly by a constant factor.</li>
		<li>
			To choose between these techniques, if we would like to have a higher image quality regardless of the time and
			memory cost, we should choose supersampling with high sample rate. Moreover, we should use bilinear sampling over
			nearest sampling along with level sampling.
		</li>
	</ul>
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">Potential Extra Credit</h2>
	<ul>
		<li>We get the intuition from test 7 in ./svg/basic.</li>
		<li>
			By changing the coordinate of the center point and combine multiple
			shapes with color gradient, we get this image with a sense of art.
		</li>
	</ul>
	<img src="./images/ec.png" width="100%" height="100%">
	<h2 align="middle" style="background-color: azure; height: 40px; padding-top: 1%;">GitHub Page Link</h2>
	<p align="middle" style="font-size: 150%;">
		<a href="https://cal-cs184-student.github.io/sp22-project-webpages-Chyvannn/">
			https://cal-cs184-student.github.io/sp22-project-webpages-Chyvannn/
		</a>
	</p>
</body>

</html>